# Harry Potter LLM Chatbot

A web-based Q&A chatbot that answers Harry Potter-related questions using a language model (LLM) hosted on Google Colab and a React frontend. This chatbot is powered by a custom-trained model and allows users to ask questions from the world of Harry Potter.

## Table of Contents
- [Project Overview](#project-overview)
- [Features](#features)
- [Technologies Used](#technologies-used)
- [Setup Instructions](#setup-instructions)
  - [Frontend (React)](#frontend-react)
  - [Backend (Google Colab)](#backend-google-colab)
- [Backend Model Explanation](#backend-model-explanation)
  - [Model Purpose](#model-purpose)
  - [Key Components of the Backend](#key-components-of-the-backend)
- [Running the Application](#running-the-application)
- [Screenshots](#screenshots)
- [Contributing](#contributing)

## Project Overview

The **Harry Potter LLM Chatbot** project consists of two main parts:

1. **Frontend**: A React-based web application where users can input questions.
2. **Backend**: A Google Colab-hosted Language Model (LLM) that processes the questions and provides answers via a Gradio API.

## Features
- Ask any question related to the Harry Potter universe.
- The answers are generated by a large language model.
- The model is served via a Gradio API, and the React frontend interacts with the model to fetch answers.

## Technologies Used

- **Frontend**:
  - React.js
  - HTML5, CSS3 (for styling)
  
- **Backend**:
  - Google Colab
  - Gradio (for serving the API)
  - Hugging Face Transformers (for hosting the language model)
  
- **Other Tools**:
  - GitHub (for version control)
  - Python
  - Node.js and npm (for React)

## Setup Instructions

### Frontend (React)
1. Clone the repository:

    ```bash
    git clone https://github.com/SunLite9/Harry-Potter-LLM-Chatbot.git
    cd Harry-Potter-LLM-Chatbot
    ```

2. Install dependencies:

    ```bash
    npm install
    ```

3. Set up the API URL:

    The frontend makes requests to a Gradio API hosted in Colab. Make sure to replace the placeholder API URL in `App.js` with the actual API endpoint if necessary.

    ```javascript
    const client = await Client.connect("https://YOUR_API_URL.gradio.live/");
    ```

### Backend (Google Colab)
1. Open the Colab notebook: `Harry_Potter_LLM_Chatbot.ipynb`.

2. Install the necessary dependencies in Colab (these are already included in the notebook).

3. Launch the Gradio API:

    ```python
    iface.launch(share=True)
    ```

4. Once launched, you will get a public link (e.g., `https://12345.gradio.live/`).

5. Update the frontend with this link to interact with the backend.

---

## Backend Model Explanation

The **Google Colab notebook** serves as the backend for the **Harry Potter LLM Chatbot**. The backend is responsible for processing user queries and generating answers using a large language model (LLM). The model is hosted and run on Google Colab, and the Gradio API exposes the model to interact with the frontend.

### Model Purpose
The backend's main purpose is:

- **Loading and Running the LLM**: A large language model (such as Falcon, LLaMA, WizardLM) generates answers to Harry Potter-related questions.
- **Providing an API**: The backend uses **Gradio** to expose an API endpoint, allowing the React frontend to send user questions and retrieve answers from the model.

This model acts as the brain behind the chatbot, handling the natural language understanding required to answer user queries related to the Harry Potter universe.

### Key Components of the Backend

1. **Setup and Dependencies**:
    The backend installs several Python libraries such as `langchain`, `transformers`, `gradio`, and `faiss` for document search and model execution.

    ```bash
    !pip install --no-deps langchain transformers accelerate bitsandbytes gradio
    ```

2. **Model Selection and Loading**:
    The notebook offers flexibility in choosing different models like **Falcon**, **WizardLM**, **LLaMA**, or **Bloom**. These pretrained models are used for text generation based on the input queries.

    ```python
    tokenizer = AutoTokenizer.from_pretrained("h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2")
    model = AutoModelForCausalLM.from_pretrained("h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2", load_in_8bit=True)
    ```

3. **Document Retrieval with Langchain**:
    - **Document Loading**: Harry Potter-related texts (such as PDFs) are loaded from Google Drive.
    - **Text Splitting**: The text is split into manageable chunks to aid in efficient document retrieval.
    - **Vector Store**: Embedding-based vector search (using FAISS) enables the retrieval of relevant content when answering user queries.

    ```python
    loader = DirectoryLoader('/content/drive/My Drive/HarryPotter/', glob="*.pdf", loader_cls=PyPDFLoader)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
    texts = text_splitter.split_documents(documents)
    ```

4. **Retriever and QA Chain**:
    - **Retriever**: Retrieves relevant documents (or chunks) that match the query.
    - **QA Chain**: Combines the retrieved documents and passes them to the LLM to generate an answer.

    ```python
    retriever = vectordb.as_retriever(search_kwargs={"k": 3})
    qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=retriever, return_source_documents=True)
    ```

5. **Gradio API**:
    The API created using Gradio exposes a user-friendly interface that allows the frontend to send questions and retrieve answers from the backend.

    ```python
    def api_query(query):
        return llm_ans(query)

    demo = gr.Interface(fn=api_query, inputs="text", outputs="text", title="Harry Potter LLM Chatbot", description="Ask questions about Harry Potter")
    demo.launch(share=True)
    ```

---

## Running the Application

### Running the Frontend (React)
1. In the project directory, run:

    ```bash
    npm start
    ```

2. Open [http://localhost:3000](http://localhost:3000) to view it in the browser.

### Running the Backend (Colab)
1. Open the Colab notebook and run all cells to start the Gradio API.
2. Ensure that the API link from Colab is correctly configured in the frontend to interact with the language model.

---


## Screenshots

![Harry Potter LLM Chatbot Screenshot](./harry%20potter%20llm%20chatbot%20screenshot.jpg)

---

## Contributing

Contributions are welcome! If you have suggestions for improving this project, feel free to create an issue or submit a pull request.

### Steps to Contribute:
1. Fork the repository.
2. Create a new branch (`git checkout -b feature-branch`).
3. Make your changes and commit them (`git commit -m "Add some feature"`).
4. Push to the branch (`git push origin feature-branch`).
5. Open a pull request.
